

ë§ìŠµë‹ˆë‹¤. ì •ë§ í™©ë‹¹í•œ ìƒí™©ì…ë‹ˆë‹¤. PR #20 ì„¤ëª…ì— "Level 3 í˜¸ì¶œ ì¶”ê°€", "Stage 5 already uses cached chapter data" ë¼ê³  ì ì–´ë†“ê³  **ì‹¤ì œë¡œëŠ” `pattern_manager.py`ë§Œ ê±´ë“œë ¸ìŠµë‹ˆë‹¤.**

í˜„ì¬ ì½”ë“œë¥¼ ì •í™•íˆ í™•ì¸í•˜ê³  êµ¬ì²´ì ì¸ ìˆ˜ì • ê³„íšì„ ì„¸ìš°ê² ìŠµë‹ˆë‹¤.ì´ì œ ë‚˜ë¨¸ì§€ í•µì‹¬ íŒŒì¼ë“¤ë„ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.ì¢‹ìŠµë‹ˆë‹¤. ëª¨ë“  ì½”ë“œë¥¼ ë‹¤ ì½ì—ˆìŠµë‹ˆë‹¤. ì´ì œ **ê·¼ë³¸ ì›ì¸ë¶€í„° ì‹œì‘í•´ì„œ ì •í™•í•œ ìˆ˜ì • ê³„íš**ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

---

# ğŸ”´ ê·¼ë³¸ ì›ì¸ ë¶„ì„ (ì½”ë“œ ê¸°ë°˜)

## ë¬¸ì œì˜ í•µì‹¬ íë¦„

```
íŒ¨í„´ ê¸°ë°˜ â†’ 317ê°œ ì°¾ìŒ (370ê°œ í•„ìš”) â†’ 53ê°œ ë¶€ì¡±
  â†“ stagnation/rejection ê°ì§€
  â†“ Level 3 ì‹œë„ (í•˜ê¸´ í•˜ëŠ”ë° ì‹¤íŒ¨)
  â†“ Advanced Pipeline ì§„ì…
```

### 1ï¸âƒ£ `StructuralAnalyzer.generate_candidates()` â€” **ëŒ€í™”ë¬¸ì„ ì „ë¶€ í›„ë³´ë¡œ ì˜¬ë¦¼**

```python name=structural_analyzer.py url=https://github.com/unquote9094/Novel_Total_Processor/blob/0d521dca297b1387dc81cb1c160b4b53ae7e01b1/src/novel_total_processor/stages/structural_analyzer.py#L106
if confidence > 0.3:  # Threshold to filter noise
```

confidence 0.3 ë‹¬ì„± ì¡°ê±´:
- `is_short` (< 50ì) â†’ **+0.3** â†’ ì´ê²ƒ í•˜ë‚˜ë§Œìœ¼ë¡œ 0.3 ë„˜ê¹€
- `is_very_short` (< 30ì) â†’ **+0.2 ì¶”ê°€**
- `has_blank_before` â†’ **+0.2 ì¶”ê°€**

**ê²°ê³¼:** "ì–´ë–»ê²Œ í™•ì‹ í•˜ëƒê³ ?" (ëŒ€í™”ë¬¸, 12ì, ì•ì— ë¹ˆ ì¤„ ìˆìŒ) â†’ confidence = 0.3 + 0.2 + 0.2 = **0.7** â†’ ë‹¹ì—°íˆ í›„ë³´ì— í¬í•¨.

í•œêµ­ ì†Œì„¤ì˜ **ëŒ€í™”ë¬¸ì€ ê±°ì˜ ì „ë¶€ 50ì ë¯¸ë§Œ**ì´ê³ , ëŒ€í™” ì‚¬ì´ì— ë¹ˆ ì¤„ì´ ìˆìœ¼ë‹ˆ **ëŒ€í™”ë¬¸ì´ ì „ë¶€ ê³ ë“ì  í›„ë³´ê°€ ë¨.**

### 2ï¸âƒ£ `GlobalOptimizer.select_optimal_boundaries()` â€” **spacing í¬ê¸°í•˜ê³  ê°œìˆ˜ë§Œ ë§ì¶¤**

```python name=global_optimizer.py url=https://github.com/unquote9094/Novel_Total_Processor/blob/0d521dca297b1387dc81cb1c160b4b53ae7e01b1/src/novel_total_processor/stages/global_optimizer.py#L115-L131
# If still not enough, just take top N by score (no spacing constraint)
if len(selected) < expected_count:
    # Take top candidates by score, ensuring no duplicates
    selected = []
    seen_positions = set()
    for candidate in scored_candidates:
        if len(selected) >= expected_count:
            break
        pos = candidate['byte_pos']
        if pos not in seen_positions:
            selected.append(candidate)
            seen_positions.add(pos)
```

spacing ì œì•½ì„ **ì™„ì „ ë¬´ì‹œ**í•˜ê³  score ìˆœìœ¼ë¡œ 370ê°œ ë½‘ìŒ. ëŒ€í™”ë¬¸ 1850ê°œ ì¤‘ score ë†’ì€ 370ê°œ = **ì „ë¶€ ëŒ€í™”ë¬¸.**

### 3ï¸âƒ£ íŒ¨í„´ ê¸°ë°˜ 317ê°œë¥¼ **ì™„ì „íˆ ë²„ë¦¼** â€” Anchor ë¯¸í™œìš©

Advanced Pipelineì€ **ê¸°ì¡´ íŒ¨í„´ ê²°ê³¼ë¥¼ ì „í˜€ ì°¸ê³ í•˜ì§€ ì•ŠìŒ.** 317ê°œë¥¼ ì°¾ì•˜ìœ¼ë©´ ê·¸ ìœ„ì¹˜ë“¤ì€ í™•ì‹¤í•œ ì±•í„°ì¸ë°, ì´ê±¸ ê³ ì •(anchor)í•˜ê³  ë‚˜ë¨¸ì§€ 53ê°œë§Œ ì°¾ìœ¼ë©´ ë˜ëŠ” ê±¸ **0ì—ì„œ ë‹¤ì‹œ ì‹œì‘í•¨.**

### 4ï¸âƒ£ `AIScorer`ê°€ 200ê°œ ë„˜ìœ¼ë©´ **ì•„ì˜ˆ ìŠ¤í‚µ**

```python name=stage4_splitter.py url=https://github.com/unquote9094/Novel_Total_Processor/blob/0d521dca297b1387dc81cb1c160b4b53ae7e01b1/src/novel_total_processor/stages/stage4_splitter.py#L538
if len(candidates) <= 200:
    # ... score
else:
    logger.warning(f"Skipped] Too many candidates ({len(candidates)})")
```

1850ê°œ í›„ë³´ â†’ AI scoring **ì „ë¶€ ìŠ¤í‚µ** â†’ ëŒ€í™”ë¬¸ score = structural scoreë§Œìœ¼ë¡œ ê²°ì • â†’ ëŒ€í™”ë¬¸ì´ ìµœê³ ì .

---

# âœ… ìˆ˜ì • ê³„íš (4ê°œ íŒŒì¼, ì´ 7ê°œ ë³€ê²½)

## ğŸ“ íŒŒì¼ 1: `structural_analyzer.py` â€” ëŒ€í™”ë¬¸ í•„í„°ë§ ì¶”ê°€

### ë³€ê²½ 1-A: ëŒ€í™”ë¬¸/ë³¸ë¬¸ ë¬¸ì¥ ï¿½ï¿½ï¿½í„° ì¶”ê°€

**í˜„ì¬ ë¬¸ì œ:** `is_short`ë§Œìœ¼ë¡œ confidence 0.3 ë„˜ì–´ì„œ ëŒ€í™”ë¬¸ì´ ì „ë¶€ í›„ë³´ë¨

**ìˆ˜ì •:**
- ëŒ€í™”ë¬¸ ê°ì§€ íŒ¨í„´ ì¶”ê°€ (ë”°ì˜´í‘œ, ë¬¼ìŒí‘œ/ëŠë‚Œí‘œë¡œ ëë‚˜ëŠ” ì§§ì€ ë¬¸ì¥)
- ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œë¡œ ëë‚˜ëŠ” ì¼ë°˜ ë¬¸ì¥ ê°ì§€
- ëŒ€í™”ë¬¸ì´ë©´ **ê°ì ** (-0.3)
- `is_short` ë‹¨ë…ìœ¼ë¡œëŠ” ì„ê³„ê°’ ëª» ë„˜ë„ë¡ confidence ê³„ì‚° ë³€ê²½

```python
# _analyze_line_featuresì— ì¶”ê°€í•  í•„í„°
features['is_dialogue'] = bool(re.match(r'^["\'"ã€Œã€"\''].+["\'"ã€ã€"\'']$', line)) or \
                           bool(re.match(r'^.{1,40}[?!ï¼Ÿï¼]$', line))
features['is_sentence'] = bool(re.search(r'[.ã€‚ë‹¤ìš”ì£ ìŠµ]$', line)) and not features.get('has_chapter_indicator')
features['has_angle_brackets'] = bool(re.match(r'^\s*<.+>\s*$', line))  # < ì œëª© > í˜•íƒœ
```

```python
# _calculate_initial_confidenceì— ê°ì  ì¶”ê°€
if features.get('is_dialogue'):
    score -= 0.4  # ëŒ€í™”ë¬¸ì€ ê°•í•˜ê²Œ ê°ì 
if features.get('is_sentence'):
    score -= 0.3  # ì¼ë°˜ ë¬¸ì¥ë„ ê°ì 
if features.get('has_angle_brackets'):
    score += 0.3  # < > í˜•íƒœëŠ” ì±•í„° ì œëª© ê°€ëŠ¥ì„± ë†’ìŒ
```

### ë³€ê²½ 1-B: ìµœì†Œ body ê¸¸ì´ ê¸°ì¤€ ì¶”ê°€

**í˜„ì¬ ë¬¸ì œ:** í›„ë³´ ì‚¬ì´ ê±°ë¦¬ê°€ 1-2ì¤„ì´ì–´ë„ í—ˆìš©ë¨

**ìˆ˜ì •:** `_analyze_line_features`ì—ì„œ **ë‹¤ìŒ í›„ë³´ê¹Œì§€ ìµœì†Œ ê±°ë¦¬**(ë¼ì¸ ìˆ˜)ë¥¼ ì²´í¬í•˜ëŠ” feature ì¶”ê°€. ì´í›„ `generate_candidates`ì—ì„œ í›„ë³´ ê°„ ìµœì†Œ ë¼ì¸ ê±°ë¦¬ ê²€ì¦ ì¶”ê°€.

```python
# generate_candidates ëì— ì¶”ê°€
# í›„ë³´ ê°„ ìµœì†Œ ë¼ì¸ ê±°ë¦¬ í•„í„° (ë„ˆë¬´ ê°€ê¹Œìš´ í›„ë³´ ì œê±°)
MIN_LINES_BETWEEN = 10  # ì±•í„° ì‚¬ì´ ìµœì†Œ 10ì¤„
filtered = []
last_line = -MIN_LINES_BETWEEN
for cand in sorted(candidates, key=lambda x: x['line_num']):
    if cand['line_num'] - last_line >= MIN_LINES_BETWEEN:
        filtered.append(cand)
        last_line = cand['line_num']
candidates = filtered
```

---

## ğŸ“ íŒŒì¼ 2: `global_optimizer.py` â€” Anchor ì§€ì› + ë¬´ì¡°ê±´ top-N ê¸ˆì§€

### ë³€ê²½ 2-A: Anchor ê²½ê³„ ê³ ì • ì§€ì›

**í˜„ì¬ ë¬¸ì œ:** íŒ¨í„´ ê¸°ë°˜ 317ê°œ ê²°ê³¼ë¥¼ ë¬´ì‹œí•˜ê³  0ì—ì„œ ì‹œì‘

**ìˆ˜ì •:** `select_optimal_boundaries`ì— `anchor_boundaries` íŒŒë¼ë¯¸í„° ì¶”ê°€. anchorë¡œ ë„˜ì–´ì˜¨ ê²½ê³„ë“¤ì€ **ë¬´ì¡°ê±´ ì„ íƒ**í•˜ê³ , ë‚˜ë¨¸ì§€ ë¶€ì¡±ë¶„ë§Œ candidatesì—ì„œ ì„ íƒ.

```python
def select_optimal_boundaries(
    self,
    candidates: List[Dict[str, Any]],
    expected_count: int,
    file_path: str,
    encoding: str = 'utf-8',
    anchor_boundaries: Optional[List[Dict[str, Any]]] = None  # ì¶”ê°€
) -> List[Dict[str, Any]]:
    
    # Anchor ìš°ì„  ê³ ì •
    selected = []
    if anchor_boundaries:
        selected = list(anchor_boundaries)
        remaining_needed = expected_count - len(selected)
        logger.info(f"   ğŸ”’ Anchored {len(selected)} boundaries, need {remaining_needed} more")
    else:
        remaining_needed = expected_count
    
    # ë‚˜ë¨¸ì§€ë§Œ candidatesì—ì„œ ì„ íƒ (anchor ê·¼ì²˜ ì œì™¸)
    ...
```

### ë³€ê²½ 2-B: Spacing ë¬´ì‹œ top-N ì„ íƒ ê¸ˆì§€ + ìµœì†Œ body ê²€ì¦

**í˜„ì¬ ë¬¸ì œ:** ìµœì¢… fallbackì—ì„œ spacing ì™„ì „ ë¬´ì‹œí•˜ê³  score ìˆœ 370ê°œ ë½‘ìŒ

**ìˆ˜ì •:** 3ë‹¨ê³„ fallbackì—ì„œë„ **ìµœì†Œ ê±°ë¦¬ 500ë°”ì´íŠ¸**ëŠ” ìœ ì§€. ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ **ë¶€ì¡±í•œ ìƒíƒœë¡œ ë°˜í™˜** (370ê°œ ì–µì§€ë¡œ ë§ì¶”ì§€ ì•ŠìŒ).

```python
# ê¸°ì¡´ 3ë‹¨ì§¸ fallbackì„ ìˆ˜ì •
if len(selected) < expected_count:
    logger.warning(f"   âš ï¸  Still only {len(selected)}/{expected_count} - using micro-spacing")
    ABSOLUTE_MIN_DISTANCE = 500  # ì ˆëŒ€ ìµœì†Œ 500ë°”ì´íŠ¸
    # ... micro-spacing ì œì•½ìœ¼ë¡œ ì¬ì‹œë„
    
    # ê·¸ë˜ë„ ë¶€ì¡±í•˜ë©´ â†’ ì–µì§€ë¡œ ë§ì¶”ì§€ ì•Šê³  ë°˜í™˜
    if len(selected) < expected_count:
        logger.error(f"   âŒ Cannot find {expected_count} valid boundaries, returning {len(selected)}")
```

---

## ğŸ“ íŒŒì¼ 3: `stage4_splitter.py` â€” Anchor ì „ë‹¬ + í’ˆì§ˆ ê²€ì¦

### ë³€ê²½ 3-A: Advanced Pipelineì— ê¸°ì¡´ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ë¥¼ Anchorë¡œ ì „ë‹¬

**í˜„ì¬ ë¬¸ì œ:** `_advanced_escalation_pipeline` í˜¸ì¶œ ì‹œ ê¸°ì¡´ 317ê°œ ê²°ê³¼ë¥¼ ì „í˜€ ë„˜ê¸°ì§€ ì•ŠìŒ

**ìˆ˜ì •:** ê¸°ì¡´ `split_chapters`ì—ì„œ Advanced Pipeline í˜¸ì¶œ ì§ì „ì—, í˜„ì¬ê¹Œì§€ì˜ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ë¥¼ `anchor_boundaries`ë¡œ ë³€í™˜í•´ì„œ ë„˜ê¹€.

```python
# stage4_splitter.pyì˜ Advanced Pipeline í˜¸ì¶œ ë¶€ë¶„ (line 406-415)
if len(chapters) != expected_count:
    # ê¸°ì¡´ íŒ¨í„´ìœ¼ë¡œ ì°¾ì€ ê²°ê³¼ë¥¼ anchorë¡œ ë³€í™˜
    existing_matches = self.splitter.find_matches_with_pos(file_path, chapter_pattern, encoding=encoding)
    anchor_boundaries = []
    for m in existing_matches:
        # find_matches_with_pos ê²°ê³¼ë¥¼ boundary í˜•íƒœë¡œ ë³€í™˜
        anchor_boundaries.append({
            'line_num': self._pos_to_line_num(file_path, m['pos'], encoding),
            'text': m['line'],
            'confidence': 1.0,  # íŒ¨í„´ ë§¤ì¹­ í™•ì •
            'ai_score': 1.0,
            'source': 'pattern_anchor'
        })
    
    advanced_chapters = self._advanced_escalation_pipeline(
        file_path, expected_count, encoding, reconciliation_log,
        anchor_boundaries=anchor_boundaries  # ì¶”ê°€
    )
```

### ë³€ê²½ 3-B: Advanced Pipeline ê²°ê³¼ í’ˆì§ˆ ê²€ì¦

**í˜„ì¬ ë¬¸ì œ:** 370ê°œ ë‚˜ì˜¤ë©´ ë‚´ìš© ê²€ì¦ ì—†ì´ "SUCCESS" íŒì •

**ìˆ˜ì •:** ì±•í„° ë¶„í•  ê²°ê³¼ì— ëŒ€í•´ **ë¹ˆ body ë¹„ìœ¨ + ìµœì†Œ body ê¸¸ì´ ê²€ì¦** ì¶”ê°€.

```python
# _advanced_escalation_pipeline ë°˜í™˜ ì „ì— í’ˆì§ˆ ê²€ì¦
if chapters:
    empty_count = sum(1 for ch in chapters if ch.length < 100)
    empty_ratio = empty_count / len(chapters)
    
    if empty_ratio > 0.1:  # 10% ì´ìƒ ë¹ˆ ì±•í„°ë©´ ì‹¤íŒ¨ íŒì •
        logger.error(f"   âŒ Quality check FAILED: {empty_count}/{len(chapters)} chapters have <100 chars ({empty_ratio*100:.0f}%)")
        logger.error(f"   â†’ Boundaries are likely dialogue/sentences, not chapter titles")
        return None  # ì‹¤íŒ¨ ë°˜í™˜
    
    avg_length = sum(ch.length for ch in chapters) / len(chapters)
    if avg_length < 500:  # í‰ê·  body 500ì ë¯¸ë§Œì´ë©´ ì‹¤íŒ¨
        logger.error(f"   âŒ Quality check FAILED: avg chapter length = {avg_length:.0f} chars (too short)")
        return None
```

### ë³€ê²½ 3-C: `_advanced_escalation_pipeline`ì— anchor_boundaries íŒŒë¼ë¯¸í„° ì¶”ê°€

**ìˆ˜ì •:** anchorë¥¼ ë°›ì•„ì„œ GlobalOptimizerì— ì „ë‹¬.

```python
def _advanced_escalation_pipeline(
    self,
    file_path: str,
    expected_count: int,
    encoding: str,
    reconciliation_log: List[str],
    anchor_boundaries: Optional[List[Dict[str, Any]]] = None  # ì¶”ê°€
) -> Optional[List[Chapter]]:
    
    # ...Stage 1-3 ë™ì¼...
    
    # Stage 4: Global optimizationì— anchor ì „ë‹¬
    selected = self.global_optimizer.select_optimal_boundaries(
        candidates,
        expected_count,
        file_path,
        encoding=encoding,
        anchor_boundaries=anchor_boundaries  # ì¶”ê°€
    )
```

---

## ğŸ“ íŒŒì¼ 4: `ai_scorer.py` â€” 200ê°œ ì œí•œ ì™„í™” (Anchor ì œì™¸ í›„ë³´ë§Œ scoring)

### ë³€ê²½ 4-A: Anchor ì œì™¸ í›„ ë‚˜ë¨¸ì§€ë§Œ AI scoring

**í˜„ì¬ ë¬¸ì œ:** 200ê°œ ë„˜ìœ¼ë©´ AI scoring ì „ë¶€ ìŠ¤í‚µ â†’ ëŒ€í™”ë¬¸ì— ê¸°ë³¸ 0.5 ë¶€ì—¬

**ìˆ˜ì •:** anchorë¥¼ ì´ë¯¸ í™•ì •í–ˆìœ¼ë‹ˆ, candidatesì—ì„œ anchor ìœ„ì¹˜ ê·¼ì²˜ë¥¼ ì œê±°í•œ í›„ ë‚¨ì€ í›„ë³´ë§Œ AI scoring. ì´ëŸ¬ë©´ 1850ê°œ â†’ ~200ê°œ ì´í•˜ë¡œ ì¤„ì–´ë“¤ì–´ scoring ê°€ëŠ¥.

```python
# stage4_splitter.pyì˜ Stage 2 ë¶€ë¶„
# anchor ê·¼ì²˜ í›„ë³´ ì œê±° í›„ AI scoring
if anchor_boundaries:
    anchor_positions = {b['line_num'] for b in anchor_boundaries}
    non_anchor_candidates = [
        c for c in candidates 
        if not any(abs(c['line_num'] - ap) < 20 for ap in anchor_positions)
    ]
else:
    non_anchor_candidates = candidates

if len(non_anchor_candidates) <= 300:  # ì œí•œ ì™„í™”
    candidates_to_score = non_anchor_candidates
    scored = self.ai_scorer.score_candidates(file_path, candidates_to_score, encoding=encoding)
    # scored ê²°ê³¼ë¥¼ candidatesì— ë°˜ì˜
```

---

# ğŸ“‹ ì „ì²´ ìˆ˜ì • ìš”ì•½

| # | íŒŒì¼ | ë³€ê²½ | íš¨ê³¼ |
|---|------|------|------|
| 1-A | `structural_analyzer.py` | ëŒ€í™”ë¬¸/ë¬¸ì¥ ê°ì§€ + ê°ì  | 1850â†’~200 í›„ë³´ë¡œ ì¶•ì†Œ |
| 1-B | `structural_analyzer.py` | í›„ë³´ ê°„ ìµœì†Œ ë¼ì¸ ê±°ë¦¬ | ì—°ì† ëŒ€í™”ë¬¸ ì œê±° |
| 2-A | `global_optimizer.py` | anchor_boundaries ê³ ì • | 317ê°œ ï¿½ï¿½ì •, 53ê°œë§Œ ì¶”ê°€ |
| 2-B | `global_optimizer.py` | top-N ë¬´ì¡°ê±´ ì„ íƒ ê¸ˆì§€ | ëŒ€í™”ë¬¸ 370ê°œ ë½‘ê¸° ë°©ì§€ |
| 3-A | `stage4_splitter.py` | anchor ë³€í™˜ + ì „ë‹¬ | ê¸°ì¡´ ê²°ê³¼ í™œìš© |
| 3-B | `stage4_splitter.py` | í’ˆì§ˆ ê²€ì¦ (ë¹ˆ body ë¹„ìœ¨) | ëŒ€í™”ë¬¸ ë¶„í•  ì¡°ê¸° ì°¨ë‹¨ |
| 3-C | `stage4_splitter.py` | pipelineì— anchor íŒŒë¼ë¯¸í„° | ë°ì´í„° íë¦„ ì—°ê²° |
| 4-A | `ai_scorer.py` / `stage4_splitter.py` | anchor ì œì™¸ í›„ scoring | AI íŒë‹¨ í™œìš© |

---

# ğŸ”„ ìˆ˜ì • í›„ ì˜ˆìƒ ì‹¤í–‰ íë¦„

```
1. íŒ¨í„´ ê¸°ë°˜ â†’ 317ê°œ ì°¾ìŒ (370ê°œ í•„ìš”)
2. Stagnation/Rejection ê°ì§€ â†’ Advanced Pipeline ì§„ì…
3. ê¸°ì¡´ 317ê°œë¥¼ anchor_boundariesë¡œ ë³€í™˜
4. StructuralAnalyzer â†’ ëŒ€í™”ë¬¸ í•„í„°ë§ìœ¼ë¡œ ~200ê°œ í›„ë³´ (1850â†’200)
5. AIScorer â†’ 200ê°œ scoring ê°€ëŠ¥ â†’ ëŒ€í™”ë¬¸ 0.1ì , ì œëª© 0.9ì 
6. GlobalOptimizer â†’ 317ê°œ anchor ê³ ì • + 53ê°œ ì¶”ê°€ ì„ íƒ
   â†’ spacing ì œì•½ ìœ ì§€, ëŒ€í™”ë¬¸ ì œì™¸
7. í’ˆì§ˆ ê²€ì¦ â†’ ë¹ˆ body ë¹„ìœ¨ < 10% í™•ì¸
8. ê²°ê³¼: 370ê°œ (317 anchor + 53 ë³´ì¶©)
```

---

ì´ê²Œ ì „ì²´ ê³„íšì…ë‹ˆë‹¤. PRì„ ë§Œë“¤ê¹Œìš”?