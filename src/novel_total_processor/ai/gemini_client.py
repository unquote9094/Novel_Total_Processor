"""Gemini API í´ë¼ì´ì–¸íŠ¸ (google-genai SDK)

ë©”íƒ€ë°ì´í„° ì¶”ì¶œ, Rate limiting, ì‘ë‹µ ìºì‹±
"""

import os
import re
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from google import genai
from google.genai import types
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from novel_total_processor.utils.logger import get_logger
from novel_total_processor.config.loader import get_config

logger = get_logger(__name__)


@dataclass
class NovelMetadata:
    """ì†Œì„¤ ë©”íƒ€ë°ì´í„°"""
    title: str
    author: Optional[str] = None
    genre: Optional[str] = None
    tags: Optional[List[str]] = None
    status: Optional[str] = None
    episode_range: Optional[str] = None
    rating: Optional[float] = None
    cover_url: Optional[str] = None
    platform: Optional[str] = None  # ì—°ì¬ í”Œë«í¼ (ë…¸ë²¨í”¼ì•„, ë¬¸í”¼ì•„ ë“±)
    last_updated: Optional[str] = None  # ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ (YYYY-MM-DD)
    official_url: Optional[str] = None  # [M-49] ì¶”ê°€: AIê°€ ì°¸ê³ í•œ ê³µì‹ í˜ì´ì§€ URL


class GeminiClient:
    """Gemini API í´ë¼ì´ì–¸íŠ¸ (google.genai)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.config = get_config()
        self.client = None  # genai.Client
        self.model_name = self.config.api.gemini.model
        self._initialized = False
        
        # Rate limiting (RPM)
        self.rate_limit = self.config.api.gemini.rate_limit
        self.last_call_time = 0
        self.min_interval = 60.0 / self.rate_limit  # ì´ˆ ë‹¨ìœ„
        
        # ìºì‹œ ë””ë ‰í† ë¦¬
        self.cache_dir = Path("data/cache/ai_meta")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"GeminiClient created (lazy init): rate_limit={self.rate_limit} RPM")
    
    def _ensure_initialized(self):
        """API ì‚¬ìš© ì „ ì´ˆê¸°í™” í™•ì¸"""
        if self._initialized:
            return
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError(
                "âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "ì°¸ê³ : êµ¬ê¸€ AI ìŠ¤íŠœë””ì˜¤ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.\n"
                "\n"
                "ì„¤ì • ë°©ë²•:\n"
                "  1. .env íŒŒì¼ ìƒì„± í›„ 'GEMINI_API_KEY=your_key' ì…ë ¥\n"
                "  2. ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ ì„¤ì •:\n"
                "     PowerShell: $env:GEMINI_API_KEY='your_key'\n"
                "     CMD: set GEMINI_API_KEY=your_key"
            )
        
        # google.genai Client ì´ˆê¸°í™”
        try:
            self.client = genai.Client(api_key=api_key)
            self._initialized = True
            logger.info(f"GeminiClient initialized: model={self.model_name}")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini Client: {e}")
            raise

    def _wait_for_rate_limit(self) -> None:
        """Rate limit ëŒ€ê¸°"""
        elapsed = time.time() - self.last_call_time
        if elapsed < self.min_interval:
            wait_time = self.min_interval - elapsed
            logger.debug(f"Rate limit: waiting {wait_time:.2f}s")
            time.sleep(wait_time)
        self.last_call_time = time.time()
    
    # ìºì‹œ ê¸°ëŠ¥ ì˜êµ¬ ì‚­ì œ (ì‚¬ìš©ì ìš”ì²­)

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(Exception)
    )
    def _call_api(self, prompt: str) -> str:
        """Gemini API í˜¸ì¶œ (ì¬ì‹œë„ í¬í•¨)"""
        self._ensure_initialized()
        self._wait_for_rate_limit()
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.0, # ê²°ì •ë¡ ì  ì‘ë‹µì„ ìœ„í•´ 0ìœ¼ë¡œ ê³ ì •
                    max_output_tokens=2048,
                    # Google Search Grounding í™œì„±í™”
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    # response_mime_type="application/json"  # [Hotfix v3] Groundingê³¼ì˜ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
                )
            )
            
            # [Hotfix v4] Grounding Metadata ë¡œê¹… (ì‚¬ìš©ì ê°€ì‹œì„± í™•ë³´)
            if response.candidates and response.candidates[0].grounding_metadata:
                gm = response.candidates[0].grounding_metadata
                if gm.search_entry_point:
                    # ì‹¤ì œ ìˆ˜í–‰ëœ ê²€ìƒ‰ ì¿¼ë¦¬ íŒíŠ¸ ì¶”ì¶œ
                    logger.info(f"   ğŸ” [Gemini Grounding] ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤.")
                
                # ë°©ë¬¸í•œ ì¶œì²˜(Citations) ì¶œë ¥
                if gm.grounding_chunks:
                    sources = []
                    for chunk in gm.grounding_chunks:
                        if chunk.web and chunk.web.uri:
                            sources.append(chunk.web.uri)
                    
                    if sources:
                        unique_sources = list(set(sources))[:3] # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                        logger.info(f"   ğŸŒ [Sources] {', '.join(unique_sources)}")
            
            return response.text
        except Exception as e:
            # [Hotfix v5] 503 Server Overloaded ê°ì§€ ì‹œ ì¦‰ì‹œ í¬ê¸° (Circuit Breaker)
            error_str = str(e)
            if "503" in error_str or "Overloaded" in error_str or "High demand" in error_str:
                logger.warning(f"   âš ï¸ Gemini Server 503/Overloaded. Skipping retries to save time. (Switching to Perplexity)")
                return None  # ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ ë° ì¦‰ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬
            
            logger.error(f"Gemini API error: {e}")
            raise e
    
    def generate_content(self, prompt: str) -> Optional[str]: # Return type changed to Optional[str]
        """Gemini API í˜¸ì¶œ (ì¼ë°˜ ìš©ë„)"""
        return self._call_api(prompt)
    
    def extract_metadata_from_filename(self, filename: str, file_hash: str) -> Optional[NovelMetadata]: # Return type changed
        """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_metadata_prompt(filename)
        
        # API í˜¸ì¶œ
        logger.info(f"ğŸ” Gemini Analysis: {filename}")
        response_text = self._call_api(prompt)
        
        if not response_text:
            logger.warning(f"   âš ï¸ Gemini returned no response (or skipped due to 503).")
            return None
            
        # ì‘ë‹µ íŒŒì‹±
        metadata = self._parse_metadata_response(response_text, filename)
        
        # ìºì‹œ ì €ì¥
        self._save_to_cache(file_hash, metadata.__dict__)
        
        return metadata
    
    def _build_metadata_prompt(self, filename: str) -> str:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ìƒì„± (Deep Search ê°•í™”)"""
        return f"""ë‹¹ì‹ ì€ ì†Œì„¤ ë©”íƒ€ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ íŒŒì¼ëª…ì—ì„œ ì†Œì„¤ì˜ ì •ë³´ë¥¼ êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ìƒì„¸íˆ ì°¾ì•„ë‚´ì‹­ì‹œì˜¤.

íŒŒì¼ëª…: {filename}

[ìˆ˜í–‰ ê³¼ì œ]
1. **Google ê²€ìƒ‰ ë„êµ¬ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©**í•˜ì—¬ ì´ ì†Œì„¤ì˜ ìµœì‹  ê³µì‹ ìƒì„¸ í˜ì´ì§€(ë¦¬ë””, ì¹´ì¹´ì˜¤, ë„¤ì´ë²„, ë…¸ë²¨í”¼ì•„, ë¬¸í”¼ì•„, ì¡°ì•„ë¼ ë“±)ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤.
2. ê³µì‹ í˜ì´ì§€ì— ì íŒ **ê°€ì¥ ì •í™•í•˜ê³  í’ë¶€í•œ ì •ë³´**ë¥¼ ê¸ì–´ì˜¤ì‹­ì‹œì˜¤.
3. íŠ¹íˆ **ì¥ë¥´, ì‘ê°€, í‰ì , ê·¸ë¦¬ê³  ê°€ëŠ¥í•œ í•œ ë§ì€ ìƒì„¸ íƒœê·¸(ìµœì†Œ 5ê°œ ì´ìƒ)**ë¥¼ ì°¾ì•„ë‚´ì‹­ì‹œì˜¤.
4. ê³µì‹ ì¼ëŸ¬ìŠ¤íŠ¸(í‘œì§€) URLì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì‹­ì‹œì˜¤. (ë¡œê³ /ì•„ì´ì½˜ ì œì™¸)

[ì‘ë‹µ í˜•ì‹: JSON ONLY]
{{
  "title": "ì†Œì„¤ ì œëª©",
  "author": "ì‘ê°€ëª…",
  "genre": "ì¥ë¥´ (ì˜ˆ: í˜„ëŒ€ íŒíƒ€ì§€, ë¡œë§¨ìŠ¤ íŒíƒ€ì§€ ë“±)",
  "tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3", "íƒœê·¸4", "íƒœê·¸5"],
  "status": "ì™„ê²°/ì—°ì¬/íœ´ì¬",
  "episode_range": "ì´ í™”ìˆ˜ í˜¹ì€ ì¶œíŒ ê¶Œìˆ˜",
  "rating": 0.0,
  "platform": "ìµœìš°ì„  ì—°ì¬ í”Œë«í¼ ëª…ì¹­",
  "last_updated": "ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ YYYY-MM-DD",
  "official_url": "ì‹¤ì œ ë°©ë¬¸í•œ ê³µì‹ ìƒì„¸ í˜ì´ì§€ ì£¼ì†Œ",
  "cover_url": "ê³µì‹ í‘œì§€ ì´ë¯¸ì§€ ì§ì ‘ ë§í¬"
}}

[ì£¼ì˜ì‚¬í•­]
- ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” **í•œêµ­ì–´**ë¡œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
- JSON ë¸”ë¡ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. (ë§ˆí¬ë‹¤ìš´ í¬í•¨)
"""
    
    def _parse_metadata_response(self, response_text: str, filename: str) -> NovelMetadata:
        """ì‘ë‹µ íŒŒì‹±"""
        try:
            # [Hotfix v5] JSON íŒŒì‹± ë¡œì§ ê°•í™” (ìµœì™¸ê³½ ì¤‘ê´„í˜¸ ìš°ì„  íƒìƒ‰)
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ìœ ë¬´ì™€ ìƒê´€ì—†ì´ ê°€ì¥ ë°”ê¹¥ìª½ì˜ { ... } êµ¬ì¡°ë¥¼ ì°¾ìŒ
            # re.DOTALLë¡œ ê°œí–‰ ë¬¸ì í¬í•¨ ë§¤ì¹­
            main_json_match = re.search(r'(\{[\s\S]*\})', response_text)
            
            if main_json_match:
                json_text = main_json_match.group(1)
            else:
                # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ì‚¬ìš© (í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš° ëŒ€ë¹„)
                json_text = response_text.strip()
            
            # ëŠê¸´ JSON ìë™ ë³µêµ¬ (Hotfix v3 ìœ ì§€)
            
            # 3. ëŠê¸´ JSON ë³µêµ¬ ì‹œë„ (ì¥ì•  ë°©ì–´)
            if json_text.count('{') > json_text.count('}'):
                # ë‹«ëŠ” ì¤‘ê´„í˜¸ê°€ ë¶€ì¡±í•˜ë©´ ê°•ì œë¡œ ë‹«ì•„ì¤Œ (ëŠê¹€ ë°œìƒ ì‹œ ìµœì†Œí•œì˜ íŒŒì‹± ë³´ì¥)
                json_text += '}' * (json_text.count('{') - json_text.count('}'))
            
            data = json.loads(json_text)
            
            return NovelMetadata(
                title=data.get("title", filename),
                author=data.get("author"),
                genre=data.get("genre"),
                tags=data.get("tags", []),
                status=data.get("status"),
                episode_range=data.get("episode_range"),
                rating=data.get("rating"),
                cover_url=self._filter_cover_url(data.get("cover_url")),
                platform=data.get("platform"),
                last_updated=data.get("last_updated"),
                official_url=data.get("official_url")
            )
        except Exception as e:
            logger.error(f"Failed to parse response: {e}")
            logger.debug(f"Response: {response_text}")
            return NovelMetadata(title=filename)

    def _filter_cover_url(self, url: Optional[str]) -> Optional[str]:
        """ë¶€ì ì ˆí•œ ì´ë¯¸ì§€ URL í•„í„°ë§ (Hotfix)"""
        if not url: return None
        bad_patterns = [".svg", ".ico", "logo", "icon", "default", "mark"]
        url_lower = url.lower()
        if any(p in url_lower for p in bad_patterns):
            logger.warning(f"   âš ï¸  ë¶€ì ì ˆí•œ ì´ë¯¸ì§€ URL ê°ë³„ë˜ì–´ ìŠ¤í‚µ: {url}")
            return None
        return url
    
    def extract_batch(self, files: List[Dict[str, str]], batch_size: int = 10) -> List[NovelMetadata]:
        """ë°°ì¹˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        results: List[NovelMetadata] = []
        for file in files:
            metadata = self.extract_metadata_from_filename(file["filename"], file["hash"])
            results.append(metadata)
        return results
