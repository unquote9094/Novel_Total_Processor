"""Gemini API í´ë¼ì´ì–¸íŠ¸ (google-genai SDK)

ë©”íƒ€ë°ì´í„° ì¶”ì¶œ, Rate limiting, ì‘ë‹µ ìºì‹±
"""

import os
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from google import genai
from google.genai import types
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from novel_total_processor.utils.logger import get_logger
from novel_total_processor.config.loader import get_config

logger = get_logger(__name__)


@dataclass
class NovelMetadata:
    """ì†Œì„¤ ë©”íƒ€ë°ì´í„°"""
    title: str
    author: Optional[str] = None
    genre: Optional[str] = None
    tags: Optional[List[str]] = None
    status: Optional[str] = None
    episode_range: Optional[str] = None
    rating: Optional[float] = None
    cover_url: Optional[str] = None
    platform: Optional[str] = None  # ì—°ì¬ í”Œë«í¼ (ë…¸ë²¨í”¼ì•„, ë¬¸í”¼ì•„ ë“±)
    last_updated: Optional[str] = None  # ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ (YYYY-MM-DD)
    official_url: Optional[str] = None  # [M-49] ì¶”ê°€: AIê°€ ì°¸ê³ í•œ ê³µì‹ í˜ì´ì§€ URL


class GeminiClient:
    """Gemini API í´ë¼ì´ì–¸íŠ¸ (google.genai)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.config = get_config()
        self.client = None  # genai.Client
        self.model_name = self.config.api.gemini.model
        self._initialized = False
        
        # Rate limiting (RPM)
        self.rate_limit = self.config.api.gemini.rate_limit
        self.last_call_time = 0
        self.min_interval = 60.0 / self.rate_limit  # ì´ˆ ë‹¨ìœ„
        
        # ìºì‹œ ë””ë ‰í† ë¦¬
        self.cache_dir = Path("data/cache/ai_meta")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"GeminiClient created (lazy init): rate_limit={self.rate_limit} RPM")
    
    def _ensure_initialized(self):
        """API ì‚¬ìš© ì „ ì´ˆê¸°í™” í™•ì¸"""
        if self._initialized:
            return
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError(
                "âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "ì°¸ê³ : êµ¬ê¸€ AI ìŠ¤íŠœë””ì˜¤ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.\n"
                "\n"
                "ì„¤ì • ë°©ë²•:\n"
                "  1. .env íŒŒì¼ ìƒì„± í›„ 'GEMINI_API_KEY=your_key' ì…ë ¥\n"
                "  2. ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ ì„¤ì •:\n"
                "     PowerShell: $env:GEMINI_API_KEY='your_key'\n"
                "     CMD: set GEMINI_API_KEY=your_key"
            )
        
        # google.genai Client ì´ˆê¸°í™”
        try:
            self.client = genai.Client(api_key=api_key)
            self._initialized = True
            logger.info(f"GeminiClient initialized: model={self.model_name}")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini Client: {e}")
            raise

    def _wait_for_rate_limit(self) -> None:
        """Rate limit ëŒ€ê¸°"""
        elapsed = time.time() - self.last_call_time
        if elapsed < self.min_interval:
            wait_time = self.min_interval - elapsed
            logger.debug(f"Rate limit: waiting {wait_time:.2f}s")
            time.sleep(wait_time)
        self.last_call_time = time.time()
    
    def _get_cache_path(self, file_hash: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return self.cache_dir / f"{file_hash}.json"
    
    def _load_from_cache(self, file_hash: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œì—ì„œ ë¡œë“œ"""
        cache_path = self._get_cache_path(file_hash)
        if cache_path.exists():
            try:
                with open(cache_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                logger.debug(f"Cache hit: {file_hash[:8]}...")
                return data
            except Exception as e:
                logger.warning(f"Cache read failed: {e}")
        return None
    
    def _save_to_cache(self, file_hash: str, data: Dict[str, Any]) -> None:
        """ìºì‹œì— ì €ì¥"""
        cache_path = self._get_cache_path(file_hash)
        try:
            with open(cache_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.debug(f"Cache saved: {file_hash[:8]}...")
        except Exception as e:
            logger.warning(f"Cache write failed: {e}")

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(Exception)
    )
    def _call_api(self, prompt: str) -> str:
        """Gemini API í˜¸ì¶œ (ì¬ì‹œë„ í¬í•¨)"""
        self._ensure_initialized()
        self._wait_for_rate_limit()
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=2048, # ì‘ë‹µ ëŠê¹€ ë°©ì§€ (2048ë¡œ í™•ì¥)
                    # Google Search Grounding í™œì„±í™” (ì§„ì§œ ì›¹ ê²€ìƒ‰)
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    response_mime_type="application/json" # JSON ì‘ë‹µ ê°•ì œ
                )
            )
            return response.text
        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            raise
    
    def generate_content(self, prompt: str) -> str:
        """Gemini API í˜¸ì¶œ (ì¼ë°˜ ìš©ë„)"""
        return self._call_api(prompt)
    
    def extract_metadata_from_filename(self, filename: str, file_hash: str) -> NovelMetadata:
        """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_metadata_prompt(filename)
        
        # API í˜¸ì¶œ
        logger.info(f"ğŸ” Gemini Analysis: {filename}")
        response_text = self._call_api(prompt)
        
        # ì‘ë‹µ íŒŒì‹±
        metadata = self._parse_metadata_response(response_text, filename)
        
        # ìºì‹œ ì €ì¥
        self._save_to_cache(file_hash, metadata.__dict__)
        
        return metadata
    
    def _build_metadata_prompt(self, filename: str) -> str:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ë‹¤ìŒ ì†Œì„¤ íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

íŒŒì¼ëª…: {filename}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "title": "ì†Œì„¤ ì œëª©",
  "author": "ì‘ê°€ëª… (ì—†ìœ¼ë©´ null)",
  "genre": "ì¥ë¥´ (íŒíƒ€ì§€/ë¡œë§¨ìŠ¤/ë¬´í˜‘ ë“±, ì—†ìœ¼ë©´ null)",
  "tags": ["íƒœê·¸1", "íƒœê·¸2"],
  "status": "ì™„ê²°/ì—°ì¬/íœ´ì¬",
  "episode_range": "1~340í™”",
  "rating": 0.0,
  "cover_url": "ê³µì‹ í‘œì§€ ì´ë¯¸ì§€ URL (ì—†ìœ¼ë©´ null)",
  "platform": "ê³µì‹ ì—°ì¬ í”Œë«í¼ ëª…ì¹­",
  "last_updated": "ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ YYYY-MM-DD",
  "official_url": "ë‹¹ì‹ ì´ ì •ë³´ë¥¼ ì¶”ì¶œí•œ ê°€ì¥ ì •í™•í•œ ê³µì‹ ìƒì„¸ í˜ì´ì§€ URL"
}}

ê·œì¹™:
1. **Google ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µì‹ ìƒì„¸ í˜ì´ì§€ URL(ë¦¬ë””, ì¹´ì¹´ì˜¤, ë„¤ì´ë²„, ë…¸ë²¨í”¼ì•„, ë¬¸í”¼ì•„ ë“±)ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ìœ¼ì‹­ì‹œì˜¤.**
2. **ì°¾ì€ ê³µì‹ ìƒì„¸ í˜ì´ì§€ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.**
3. **official_url í•„ë“œì—ëŠ” ë‹¹ì‹ ì´ ì‹¤ì œ ë°©ë¬¸í•œ ì†Œì„¤ ìƒì„¸ í˜ì´ì§€ URLì„ ë°˜ë“œì‹œ ê¸°ì…í•˜ì‹­ì‹œì˜¤.**
4. **í‘œì§€ ì´ë¯¸ì§€ëŠ” ê³µì‹ ì¼ëŸ¬ìŠ¤íŠ¸ URLì„ ì°¾ë˜, ì‚¬ì´íŠ¸ ë¡œê³ (logo), ì•„ì´ì½˜(icon), í˜¹ì€ ê¸°ë³¸ ì´ë¯¸ì§€(svg, default, ico)ëŠ” ì ˆëŒ€ ê¸°ì…í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
5. **ë°˜ë“œì‹œ ì„œë¡ ì´ë‚˜ ì„¤ëª… ì—†ì´ { ë¡œ ì‹œì‘í•˜ì—¬ } ë¡œ ëë‚˜ëŠ” ìˆœìˆ˜ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ì‘ë‹µì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•µì‹¬ ì •ë³´ ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.**
6. **ëª¨ë“  ì •ë³´ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì‹­ì‹œì˜¤.** (ì¥ë¥´, íƒœê·¸, ìƒíƒœ ë“±)
"""
    
    def _parse_metadata_response(self, response_text: str, filename: str) -> NovelMetadata:
        """ì‘ë‹µ íŒŒì‹±"""
        try:
            json_text = response_text.strip()
            if json_text.startswith("```"):
                parts = json_text.split("```")
                json_text = parts[1]
                if json_text.startswith("json"):
                    json_text = json_text[4:]
            
            data = json.loads(json_text.strip())
            
            return NovelMetadata(
                title=data.get("title", filename),
                author=data.get("author"),
                genre=data.get("genre"),
                tags=data.get("tags", []),
                status=data.get("status"),
                episode_range=data.get("episode_range"),
                rating=data.get("rating"),
                cover_url=self._filter_cover_url(data.get("cover_url")),
                platform=data.get("platform"),
                last_updated=data.get("last_updated"),
                official_url=data.get("official_url")
            )
        except Exception as e:
            logger.error(f"Failed to parse response: {e}")
            logger.debug(f"Response: {response_text}")
            return NovelMetadata(title=filename)

    def _filter_cover_url(self, url: Optional[str]) -> Optional[str]:
        """ë¶€ì ì ˆí•œ ì´ë¯¸ì§€ URL í•„í„°ë§ (Hotfix)"""
        if not url: return None
        bad_patterns = [".svg", ".ico", "logo", "icon", "default", "mark"]
        url_lower = url.lower()
        if any(p in url_lower for p in bad_patterns):
            logger.warning(f"   âš ï¸  ë¶€ì ì ˆí•œ ì´ë¯¸ì§€ URL ê°ë³„ë˜ì–´ ìŠ¤í‚µ: {url}")
            return None
        return url
    
    def extract_batch(self, files: List[Dict[str, str]], batch_size: int = 10) -> List[NovelMetadata]:
        """ë°°ì¹˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        results: List[NovelMetadata] = []
        for file in files:
            metadata = self.extract_metadata_from_filename(file["filename"], file["hash"])
            results.append(metadata)
        return results
