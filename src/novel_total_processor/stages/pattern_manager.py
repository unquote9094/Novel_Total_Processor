"""íŒ¨í„´ ê´€ë¦¬ì (Reference v3.0 ê¸°ë°˜ ê³ ë„í™”)

AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œì„¤ì˜ ìµœì  ì±•í„° ë¶„í•  íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³  ê²€ì¦
NovelAIze-SSR v3.0ì˜ ê³ í’ˆì§ˆ í”„ë¡¬í”„íŠ¸ ë³µì› ë° 99% ì»¤ë²„ë¦¬ì§€ ì¶”ì  ë¡œì§ ì ìš©
"""

import re
import time
import os
from typing import Optional, Tuple, List, Dict, Any
from novel_total_processor.stages.sampler import Sampler
from novel_total_processor.stages.splitter import Splitter
from novel_total_processor.ai.gemini_client import GeminiClient
from novel_total_processor.utils.logger import get_logger

logger = get_logger(__name__)


class PatternManager:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œì„¤ì˜ ìµœì  ì±•í„° ë¶„í•  íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³  ê²€ì¦ (v3.0 Reference)"""
    
    def __init__(self, client: GeminiClient):
        self.client = client
        self.splitter = Splitter()
        self.sampler = Sampler()
    
    def find_best_pattern(
        self,
        target_file: str,
        initial_samples: str,
        filename: Optional[str] = None,
        encoding: str = 'utf-8'
    ) -> Tuple[Optional[str], Optional[str]]:
        """ìµœì ì˜ íŒ¨í„´ íƒìƒ‰ (v3.0 Plan C ì •ë°€ ì¶”ì  í¬í•¨)"""
        
        # 1. ê¸°ëŒ€ í™”ìˆ˜ ì¶”ì¶œ
        expected_count = 0
        if filename:
            nums = re.findall(r'\d+', filename)
            if nums: expected_count = int(nums[-1])

        # 2. AI ë¶„ì„ (v3.0 ì›ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        logger.info(f"   -> ì±•í„° ì œëª© íŒ¨í„´ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (Reference Mode)")
        pattern = self._analyze_pattern_v3(initial_samples)
        
        if not pattern or pattern == "NO_PATTERN_FOUND":
            pattern, _ = self._try_fallback(target_file, encoding=encoding)
            return (pattern, None)

        # 3. ì»¤ë²„ë¦¬ì§€ ê²€ì¦ ë° ì •ë°€ ì¶”ì  (Plan C)
        stats = self.splitter.verify_pattern(target_file, pattern, encoding=encoding)
        
        # v3.0 ê¸°ì¤€ 99% ë¯¸ë‹¬ ì‹œ ì •ë°€ ì¶”ì  ì‹œì‘
        if not stats.get('coverage_ok'):
            cur_ratio = stats.get('last_match_ratio', 0)
            logger.warning(f"   âš ï¸ íŒ¨í„´ ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ ({cur_ratio*100:.1f}%). ì •ë°€ ì¶”ì (Plan C)ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            pattern = self._run_adaptive_retry_v3(target_file, pattern, stats, encoding=encoding)
            stats = self.splitter.verify_pattern(target_file, pattern, encoding=encoding)

        # 4. Zero Tolerance (100% ì¼ì¹˜ ë³´ì •)
        if expected_count > 0 and stats.get('match_count', 0) != expected_count:
            logger.info(f"   ğŸ”„ [M-45] í™”ìˆ˜ ì •í•©ì„± ë³´ì • ì¤‘ ({stats.get('match_count')}/{expected_count})")
            pattern = self.refine_pattern_with_goal_v3(target_file, pattern, expected_count, encoding=encoding)
            
        return (pattern, None)
    
    def _analyze_pattern_v3(self, sample_text: str) -> Optional[str]:
        """NovelAIze-SSR v3.0 ì›ë³¸ í”„ë¡¬í”„íŠ¸ ë³µì›"""
        prompt = f"""=== pattern_analysis ===
You are an expert in Regex (Regular Expressions) and Text Analysis.
Analyze the following Novel Text Samples and identify the Pattern used for Chapter Titles.

[Tasks]
1. Find the most consistent pattern that denotes a new chapter start.
   Examples: "ì œ 1 í™”", "Chapter 1", "1í™”.", "Ep.1"
2. Create a Python Compatible Regular Expression (Regex) to match these chapter titles.
   - Use `\s*` for flexible whitespace.
   - Use `\d+` for numbers.
3. OUTPUT ONLY the raw Regex string. No markdown, no content.
   - If no pattern found, return "NO_PATTERN_FOUND".

[Novel Text Samples]
{sample_text[:30000]}
"""
        try:
            response = self.client.generate_content(prompt)
            # ë§ˆí¬ë‹¤ìš´ ë° ë¶ˆí•„ìš” í…ìŠ¤íŠ¸ ì •ì œ
            result = response.strip().replace("```python", "").replace("```re", "").replace("```", "").replace("r'", "").replace("'", "").strip()
            if "NO_PATTERN_FOUND" in result: return None
            # ì¤„ë°”ê¿ˆì´ ìˆëŠ” ê²½ìš° ì²« ì¤„ë§Œ ì‚¬ìš©
            result = result.splitlines()[0] if result else None
            
            # [M-Hotfix] ì •ê·œì‹ ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦
            if result:
                try:
                    re.compile(result)
                except re.error as e:
                    logger.error(f"   âŒ AI ìƒì„± ì •ê·œì‹ ì˜¤ë¥˜: {e} (Pattern: {result})")
                    return None
            return result
        except Exception as e:
            logger.error(f"   âŒ AI ë¶„ì„ ì¤‘ ì—ëŸ¬: {e}")
            return None

    def _run_adaptive_retry_v3(self, target_file: str, current_pattern: str, verify_stats: dict, encoding: str = 'utf-8') -> str:
        """v3.0 ì •ë°€ ì¶”ì  ë¡œì§ (ìµœëŒ€ 10íšŒ)"""
        retry_count = 0
        max_retries = 10
        pattern = current_pattern
        stats = verify_stats
        
        while not stats['coverage_ok'] and retry_count < max_retries:
            retry_count += 1
            fail_pos = stats['last_match_pos']
            
            # ì‹¤íŒ¨ ì§€ì ë¶€í„° ë‹¤ì‹œ ìƒ˜í”Œë§
            retry_sample = self.sampler.extract_samples_from(target_file, fail_pos, length=30000, encoding=encoding)
            if not retry_sample: break
                
            logger.info(f"   ğŸ”„ [Retry {retry_count}/{max_retries}] ëˆ„ë½ ì§€ì ({fail_pos}) ë¶„ì„ ì¤‘...")
            new_pattern = self._analyze_pattern_v3(retry_sample)
            
            if new_pattern and new_pattern != "NO_PATTERN_FOUND":
                combined_pattern = f"{pattern}|{new_pattern}"
                new_stats = self.splitter.verify_pattern(target_file, combined_pattern, encoding=encoding)
                
                # ì¡°ê¸ˆì´ë¼ë„ ë‚˜ì•„ì§€ë©´ ì ìš©
                new_ratio = new_stats.get('last_match_ratio', 0)
                old_ratio = stats.get('last_match_ratio', 0)
                new_tail = new_stats.get('tail_size', 9999999)
                old_tail = stats.get('tail_size', 9999999)

                if new_ratio > old_ratio or new_tail < old_tail:
                    pattern = combined_pattern
                    stats = new_stats
                    if stats.get('coverage_ok'):
                        logger.info(f"   âœ¨ [Plan C Success] ëª©í‘œ ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±!")
                        break
                else:
                    logger.info("   âŒ ê°œì„ ë˜ì§€ ì•ŠìŒ. ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰...")
            else:
                break
        return pattern

    def refine_pattern_with_goal_v3(self, target_file: str, current_pattern: str, expected_count: int, encoding: str = 'utf-8') -> str:
        """100% ì¼ì¹˜ë¥¼ ìœ„í•œ ìµœì¢… ë³´ì • (v3.0 í™•ì¥)"""
        matches = self.splitter.find_matches_with_pos(target_file, current_pattern, encoding=encoding)
        actual_count = len(matches)
        
        if actual_count == expected_count: return current_pattern
        
        # ê³¼ë§¤ì¹­ ì‹œ: ìˆ«ì ì‹œí€€ìŠ¤ í•„í„°ë§ ê°•í™”
        if actual_count > expected_count:
            logger.info(f"   ğŸ”„ ê³¼ë§¤ì¹­ ì œê±° ì‹œë„ ({actual_count}ch -> {expected_count}ch)")
            # ê°€ì¥ í™•ì‹¤í•œ ìˆ«ì íŒ¨í„´ë“¤ ì‹œë„
            for ptn in [r"(?:ì œ\s*)?\d+\s*í™”", r"\d+\s*í™”", r"\[\d+\]", r"Chapter\s*\d+"]:
                s = self.splitter.verify_pattern(target_file, ptn, encoding=encoding)
                if s['match_count'] == expected_count: return ptn
        
        # ë¶€ì¡± ì‹œ: ê°­ ë¶„ì„ ì •ë°€í™”
        if actual_count < expected_count:
            logger.info(f"   ğŸ”„ ë¶€ì¡± í™”ìˆ˜ ì¶”ì  ì¤‘ (ëˆ„ë½: {expected_count - actual_count}ê°œ)")
            gaps = self.splitter.find_large_gaps(target_file, matches)
            pattern = current_pattern
            for gap in gaps:
                sample = self.sampler.extract_samples_from(target_file, gap['start'], length=30000, encoding=encoding)
                if not sample: continue
                new_p = self._analyze_pattern_v3(sample)
                if new_p:
                    test_p = f"{pattern}|{new_p}"
                    test_s = self.splitter.verify_pattern(target_file, test_p, encoding=encoding)
                    if test_s['match_count'] <= expected_count:
                        pattern = test_p
                        if test_s['match_count'] == expected_count: break
            return pattern

        return current_pattern

    def _try_fallback(self, target_file: str, encoding: str = 'utf-8') -> Tuple[Optional[str], Optional[str]]:
        for ptn in [r"\d+\s*í™”", r"ì œ\s*\d+\s*í™”", r"\[\d+\]"]:
            stats = self.splitter.verify_pattern(target_file, ptn, encoding=encoding)
            if stats['match_count'] > 0: return (ptn, None)
        return (None, None)
