"""íŒ¨í„´ ê´€ë¦¬ì

AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œì„¤ì˜ ìµœì  ì±•í„° ë¶„í•  íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³  ê²€ì¦
NovelAIze-SSR v3.0ì˜ PatternManager í¬íŒ… + ì†Œì œëª© íŒ¨í„´ ì¶”ê°€
"""

from typing import Optional, Tuple
from novel_total_processor.stages.sampler import Sampler
from novel_total_processor.stages.splitter import Splitter
from novel_total_processor.ai.gemini_client import GeminiClient
from novel_total_processor.utils.logger import get_logger

logger = get_logger(__name__)


class PatternManager:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œì„¤ì˜ ìµœì  ì±•í„° ë¶„í•  íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³  ê²€ì¦í•˜ëŠ” í´ë˜ìŠ¤
    
    Adaptive Retry (Plan C) ë° ë²”ìš© íŒ¨í„´ ì‹œë„(Plan B) ë¡œì§ì„ í¬í•¨
    """
    
    def __init__(self, client: GeminiClient):
        """
        Args:
            client: GeminiClient ì¸ìŠ¤í„´ìŠ¤
        """
        self.client = client
        self.splitter = Splitter()
        self.sampler = Sampler()
    
    def find_best_pattern(
        self,
        target_file: str,
        initial_samples: str
    ) -> Tuple[Optional[str], Optional[str]]:
        """ìµœì ì˜ ì±•í„° íŒ¨í„´ê³¼ ì†Œì œëª© íŒ¨í„´ì„ ì°¾ê¸°
        
        Args:
            target_file: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
            initial_samples: ì´ˆê¸° ìƒ˜í”Œ í…ìŠ¤íŠ¸
        
        Returns:
            (chapter_pattern, subtitle_pattern) íŠœí”Œ
        """
        logger.info("   -> ì±•í„° ì œëª© íŒ¨í„´ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")
        
        try:
            # AIì— 2ê°€ì§€ ìš”ì²­: ì±•í„° íŒ¨í„´ + ì†Œì œëª© íŒ¨í„´
            patterns = self._analyze_patterns(initial_samples)
            
            if not patterns or not patterns.get("chapter_pattern"):
                return self._try_fallback(target_file)
        
        except Exception as e:
            logger.error(f"   âŒ [AI Error] íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._try_fallback(target_file)
        
        chapter_pattern = patterns["chapter_pattern"]
        subtitle_pattern = patterns.get("subtitle_pattern")
        
        logger.info(f"   [AI ë¶„ì„ ê²°ê³¼] ì±•í„° íŒ¨í„´: {chapter_pattern}")
        if subtitle_pattern:
            logger.info(f"   [AI ë¶„ì„ ê²°ê³¼] ì†Œì œëª© íŒ¨í„´: {subtitle_pattern}")
        
        # ì±•í„° íŒ¨í„´ ê²€ì¦
        verify_stats = self.splitter.verify_pattern(target_file, chapter_pattern)
        
        if verify_stats['coverage_ok']:
            return (chapter_pattern, subtitle_pattern)
        
        logger.warning(
            f"   âš ï¸  [Warning] íŒ¨í„´ ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ ({verify_stats['last_match_ratio']*100:.1f}%)"
        )
        
        # Adaptive Retry
        final_pattern = self._run_adaptive_retry(target_file, chapter_pattern, verify_stats)
        return (final_pattern, subtitle_pattern)
    
    def _analyze_patterns(self, sample_text: str) -> dict:
        """AIì— ìƒ˜í”Œì„ ë³´ë‚´ì„œ ì±•í„° íŒ¨í„´ + ì†Œì œëª© íŒ¨í„´ ë¶„ì„
        
        Args:
            sample_text: ìƒ˜í”Œ í…ìŠ¤íŠ¸
        
        Returns:
            {"chapter_pattern": str, "subtitle_pattern": str}
        """
        prompt = f"""ë‹¤ìŒì€ ì†Œì„¤ íŒŒì¼ì˜ ìƒ˜í”Œì…ë‹ˆë‹¤. ì´ ì†Œì„¤ì˜ ì±•í„° êµ¬ë¶„ íŒ¨í„´ê³¼ ì†Œì œëª© íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ìƒ˜í”Œ:
```
{sample_text[:10000]}  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì „ì†¡
```

ìš”ì²­ 1: ì±•í„° êµ¬ë¶„ ì •ê·œì‹ íŒ¨í„´
- ê° í™”(ì—í”¼ì†Œë“œ)ë¥¼ êµ¬ë¶„í•˜ëŠ” íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì˜ˆ: r"â”+\\s*.*?\\s*\\d+í™”\\s*â”+" ë˜ëŠ” r"ì œ\\s*\\d+\\s*í™”"

ìš”ì²­ 2: ì±•í„° ì†Œì œëª©/ë¶€ì œëª© íŒ¨í„´
- ì±•í„° ì œëª© ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì†Œì œëª©ì´ë‚˜ ë¶€ì œëª© íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì˜ˆ: r"^\\d+\\.\\s*.+$" (ìˆ«ì. ì œëª© í˜•ì‹)
- ì†Œì œëª©ì´ ì—†ìœ¼ë©´ nullë¡œ ì‘ë‹µ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "chapter_pattern": "ì •ê·œì‹",
  "subtitle_pattern": "ì •ê·œì‹ ë˜ëŠ” null"
}}
"""
        
        try:
            response = self.client.generate_content(prompt)
            
            # JSON íŒŒì‹±
            import json
            import re
            
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'\{[^{}]*"chapter_pattern"[^{}]*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(0))
                return result
            
            # JSON ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ì¶”ì¶œ ì‹œë„
            chapter_match = re.search(r'chapter_pattern["\s:]+(["\'])(.*?)\1', response)
            if chapter_match:
                chapter_pattern = chapter_match.group(2)
                
                subtitle_match = re.search(r'subtitle_pattern["\s:]+(["\'])(.*?)\1', response)
                subtitle_pattern = subtitle_match.group(2) if subtitle_match else None
                
                return {
                    "chapter_pattern": chapter_pattern,
                    "subtitle_pattern": subtitle_pattern
                }
            
            logger.error(f"AI ì‘ë‹µì—ì„œ íŒ¨í„´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {response[:200]}")
            return {}
        
        except Exception as e:
            logger.error(f"íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def _run_adaptive_retry(
        self,
        target_file: str,
        current_pattern: str,
        verify_stats: dict
    ) -> str:
        """Adaptive Retry: 99% ë‹¬ì„±ì„ ìœ„í•œ ì •ë°€ ì¶”ì 
        
        Args:
            target_file: ëŒ€ìƒ íŒŒì¼
            current_pattern: í˜„ì¬ íŒ¨í„´
            verify_stats: ê²€ì¦ í†µê³„
        
        Returns:
            ìµœì¢… íŒ¨í„´
        """
        retry_count = 0
        max_retries = 10
        pattern = current_pattern
        stats = verify_stats
        
        logger.info(f"   -> [Plan C] 99% ë‹¬ì„±ì„ ìœ„í•œ ì •ë°€ ì¶”ì  ì‹œì‘ (ìµœëŒ€ {max_retries}ë‹¨ê³„)")
        
        while not stats['coverage_ok'] and retry_count < max_retries:
            retry_count += 1
            logger.info(
                f"   ğŸ”„ [Retry {retry_count}/{max_retries}] "
                f"ëˆ„ë½ëœ í™”ì°¨ ìœ„ì¹˜({stats['last_match_pos']})ì—ì„œ ë‹¤ìŒ íŒ¨í„´ ë¶„ì„ ì¤‘..."
            )
            
            fail_pos = stats['last_match_pos']
            retry_sample = self.sampler.extract_samples_from(target_file, fail_pos)
            
            if not retry_sample:
                break
            
            try:
                new_patterns = self._analyze_patterns(retry_sample)
                new_pattern = new_patterns.get("chapter_pattern")
                
                if new_pattern:
                    combined_pattern = f"{pattern}|{new_pattern}"
                    verify_stats_new = self.splitter.verify_pattern(target_file, combined_pattern)
                    
                    # ì¡°ê¸ˆì´ë¼ë„ ë‚˜ì•„ì§€ë©´ ì ìš©
                    if (verify_stats_new['last_match_ratio'] > stats['last_match_ratio'] or
                        verify_stats_new['tail_size'] < stats['tail_size']):
                        pattern = combined_pattern
                        stats = verify_stats_new
                        
                        if stats['coverage_ok']:
                            logger.info("   âœ¨ [Success] ëª©í‘œ ì»¤ë²„ë¦¬ì§€(99%) ë‹¬ì„±!")
                            break
                    else:
                        logger.info("   âŒ íŒ¨í„´ ì¶”ê°€ ì‹œë„í–ˆìœ¼ë‚˜ ê°œì„ ë˜ì§€ ì•ŠìŒ. ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰...")
            
            except Exception as e:
                logger.error(f"Retry ì¤‘ ì˜¤ë¥˜: {e}")
                break
        
        return pattern
    
    def _try_fallback(
        self,
        target_file: str,
        current_best: Optional[str] = None
    ) -> Tuple[Optional[str], Optional[str]]:
        """Plan B: ë²”ìš© íŒ¨í„´ ì‹œë„
        
        Args:
            target_file: ëŒ€ìƒ íŒŒì¼
            current_best: í˜„ì¬ ìµœì„ ì˜ íŒ¨í„´
        
        Returns:
            (chapter_pattern, subtitle_pattern) íŠœí”Œ
        """
        logger.info("   -> [Plan B] ë²”ìš© íŒ¨í„´ ì‹œë„...")
        
        fallback_pattern = r"\d+\s*í™”"
        verify_stats_fallback = self.splitter.verify_pattern(target_file, fallback_pattern)
        
        if verify_stats_fallback['last_match_ratio'] > 0.9:
            return (fallback_pattern, None)
        
        return (current_best, None) if current_best else (None, None)
