"""Stage 3: íŒŒì¼ëª… ìƒì„±

rules.yml ê¸°ë°˜ íŒŒì¼ëª… ê·œì¹™ ì—”ì§„, ê²€ìˆ˜ìš© ë§¤í•‘ íŒŒì¼ ìƒì„±
"""

import re
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from novel_total_processor.utils.logger import get_logger
from novel_total_processor.db.schema import Database
from novel_total_processor.config.loader import get_config, get_rules

logger = get_logger(__name__)


class FilenameGenerator:
    """íŒŒì¼ëª… ìƒì„±ê¸° (Stage 3)"""
    
    def __init__(self, db: Database):
        """
        Args:
            db: Database ì¸ìŠ¤í„´ìŠ¤
        """
        self.db = db
        self.config = get_config()
        self.rules = get_rules()
        logger.info("FilenameGenerator initialized")
    
    def get_pending_files(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """Stage 3 ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼ ì¡°íšŒ
        
        Args:
            limit: ìµœëŒ€ íŒŒì¼ ìˆ˜
        
        Returns:
            íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        conn = self.db.connect()
        cursor = conn.cursor()
        
        query = """
            SELECT f.id, f.file_path, f.file_name, f.file_ext, n.title, n.author, n.genre, 
                   n.tags, n.status, n.episode_range, n.rating, n.chapter_count
            FROM files f
            JOIN processing_state ps ON f.id = ps.file_id
            JOIN novels n ON f.novel_id = n.id
            WHERE ps.stage1_meta = 1 AND ps.stage3_rename = 0
            AND f.is_duplicate = 0 AND f.file_ext IN ('.txt', '.epub')
            ORDER BY f.id ASC
        """
        
        if limit:
            query += f" LIMIT {limit}"
        
        cursor.execute(query)
        rows = cursor.fetchall()
        
        files = []
        for row in rows:
            files.append({
                "id": row[0],
                "file_path": row[1],
                "filename": row[2],
                "ext": row[3],
                "title": row[4],
                "author": row[5],
                "genre": row[6],
                "tags": self._parse_tags(row[7]) if row[7] else [],
                "status": row[8],
                "episode_range": row[9],
                "rating": row[10],
                "chapter_count": row[11]
            })
        
        logger.info(f"Found {len(files)} files pending for Stage 3")
        return files
    
    def generate_filename(self, metadata: Dict[str, Any]) -> str:
        """íŒŒì¼ëª… ìƒì„±
        
        Args:
            metadata: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ìƒˆ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
        
        Format: ì œëª©__í™”ìˆ˜_ìƒíƒœ__â˜…ë³„ì __ì¥ë¥´__ì‘ê°€__íƒœê·¸.ext
        """
        parts = []
        
        # 1. ì œëª© ì •ê·œí™”
        title = self._normalize_title(metadata["title"])
        parts.append(title)
        
        # 2. í™”ìˆ˜_ìƒíƒœ (íŒŒì¼ëª… íŒíŠ¸ ìµœìš°ì„  ì ìš©: M-46)
        original_range = metadata.get("episode_range")
        original_status = metadata.get("status")
        chapter_count = metadata.get("chapter_count")
        
        # íŒŒì¼ëª…ì—ì„œ íŒíŠ¸ ì¶”ì¶œ (ì˜ˆ: 1~321í™”)
        hint_range = None
        hint_nums = re.findall(r'\((\d+~\d+)\)', metadata["filename"])
        if not hint_nums:
            hint_nums = re.findall(r'\((\d+)\)', metadata["filename"])
            if hint_nums: hint_range = f"1~{hint_nums[0]}í™”"
        else:
            hint_range = f"{hint_nums[0]}í™”"
            
        reconciled_range = original_range
        reconciled_status = original_status
        
        # íŒŒì¼ëª… íŒíŠ¸ê°€ ìˆë‹¤ë©´ ë¬´ì¡°ê±´ ìµœìš°ì„  (ì´ë¯¸ ê²€ì¦ëœ ì •ë³´ë¡œ ê°„ì£¼)
        if hint_range:
            reconciled_range = hint_range
        elif chapter_count and chapter_count > 0:
            reconciled_range = f"1~{chapter_count}í™”"
        
        # [Smart Extension] ì‹¤ë¬¼ í™”ìˆ˜ì™€ ì›¹ í™”ìˆ˜ê°€ ë‹¤ë¥¼ ê²½ìš° í™•ì¥ íƒœê¹… (M-49)
        # ì›¹ í™”ìˆ˜(original_range)ì—ì„œ ìˆ«ì ì¶”ì¶œ
        web_total = 0
        if original_range:
            web_nums = re.findall(r'(\d+)', original_range)
            if web_nums: web_total = int(web_nums[-1])
            
        real_total = chapter_count if chapter_count else 0
        if not real_total and hint_range:
            hint_nums_extracted = re.findall(r'(\d+)', hint_range)
            if hint_nums_extracted: real_total = int(hint_nums_extracted[-1])

        # í™”ìˆ˜ ë¶ˆì¼ì¹˜ ì‹œ ìƒíƒœê°’ í™•ì¥
        if web_total > 0 and real_total > 0 and web_total != real_total:
            diff_tag = f"({real_total}_{web_total}í™”)"
            if reconciled_status:
                reconciled_status = f"{reconciled_status}_ë¶€ë¶„{diff_tag}"
            else:
                reconciled_status = f"ë¶€ë¶„{diff_tag}"
        
        episode_status = self._format_episode_status(
            reconciled_range,
            reconciled_status
        )
        parts.append(episode_status)
        
        # 3. â˜…ë³„ì 
        rating = self._format_rating(metadata.get("rating"))
        if "Unknown" not in rating and "ë¯¸í‰ê°€" not in rating:
            parts.append(rating)
        
        # 4. ì¥ë¥´
        genre = self._normalize_genre(metadata.get("genre"))
        if genre and "Unknown" not in genre:
            parts.append(genre)
        
        # 5. ì‘ê°€
        author = self._normalize_author(metadata.get("author"))
        if author and "Unknown" not in author:
            parts.append(author)
        
        # 6. íƒœê·¸
        tags = self._format_tags(metadata.get("tags", []))
        if tags:
            parts.append(tags)
        
        # êµ¬ë¶„ìë¡œ ê²°í•© (ë¹ˆ í•„ë“œëŠ” ê±¸ëŸ¬ë‚´ê¸°)
        separator = self.rules.filename["separator"]
        parts = [p for p in parts if p and p.strip() and "Unknown" not in p]
        filename = separator.join(parts)
        
        # ê¸ˆì§€ ë¬¸ì ì œê±°
        filename = self._sanitize_filename(filename)
        
        # ê¸¸ì´ ì œí•œ
        filename = self._truncate_filename(filename, metadata["ext"])
        
        # í™•ì¥ì ì¶”ê°€
        return f"{filename}{metadata['ext']}"
    
    def _normalize_title(self, title: str) -> str:
        """ì œëª© ì •ê·œí™”
        
        Args:
            title: ì›ë³¸ ì œëª©
        
        Returns:
            ì •ê·œí™”ëœ ì œëª©
        """
        # ì ‘ë‘ì‚¬ ì œê±°
        for pattern in self.rules.title["remove_prefixes"]:
            title = re.sub(pattern, "", title)
        
        # ì ‘ë¯¸ì‚¬ ì œê±°
        for pattern in self.rules.title["remove_suffixes"]:
            title = re.sub(pattern, "", title)
        
        # ê³µë°± ì •ë¦¬
        title = " ".join(title.split())
        
        # ìµœëŒ€ ê¸¸ì´
        max_len = self.rules.title["max_length"]
        if len(title.encode("utf-8")) > max_len:
            # ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            title_bytes = title.encode("utf-8")[:max_len]
            title = title_bytes.decode("utf-8", errors="ignore")
        
        return title.strip()
    
    def _format_episode_status(self, episode_range: Optional[str], status: Optional[str]) -> str:
        """í™”ìˆ˜_ìƒíƒœ í¬ë§·
        
        Args:
            episode_range: í™”ìˆ˜ ë²”ìœ„ (ì˜ˆ: "1~340í™”")
            status: ìƒíƒœ (ì™„ê²°/ì—°ì¬/íœ´ì¬)
        
        Returns:
            "1~340í™”_ì™„ê²°" í˜•ì‹
        """
        parts = []
        
        if episode_range:
            parts.append(episode_range)
        else:
            parts.append(self.rules.episode["oneshot_marker"])
        
        if status:
            # ì˜ì–´ ìƒíƒœê°’ í•œê¸€ ë§¤í•‘ (M-32)
            status_map = {
                "completed": "ì™„ê²°",
                "Completed": "ì™„ê²°",
                "ongoing": "ì—°ì¬",
                "Ongoing": "ì—°ì¬",
                "ì—°ì¬ì¤‘": "ì—°ì¬",
                "ì—°ì¬": "ì—°ì¬",
                "hiatus": "íœ´ì¬",
                "Hiatus": "íœ´ì¬"
            }
            mapped_status = status_map.get(status, status)
            
            # ë£° ê¸°ë°˜ ìµœì¢… ë³€í™˜
            status_text = self.rules.status.get(mapped_status.lower(), mapped_status)
            parts.append(status_text)
        
        return "_".join(parts) if parts else "ë¯¸í™•ì¸"
    
    def _format_rating(self, rating: Optional[float]) -> str:
        """ë³„ì  í¬ë§·
        
        Args:
            rating: ë³„ì  (0.0~5.0)
        
        Returns:
            "â˜…4.5" í˜•ì‹
        """
        if rating is None:
            return self.rules.rating["unknown"]
        
        symbol = self.rules.rating["symbol"]
        decimal_places = self.rules.rating["decimal_places"]
        
        return f"{symbol}{rating:.{decimal_places}f}"
    
    def _normalize_genre(self, genre: Optional[str]) -> str:
        """ì¥ë¥´ ì •ê·œí™”
        
        Args:
            genre: ì›ë³¸ ì¥ë¥´
        
        Returns:
            í‘œì¤€ ì¥ë¥´ëª…
        """
        if not genre:
            return self.rules.genre["default"]
        
        # ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        mapping = self.rules.genre["mapping"]
        return mapping.get(genre, genre)
    
    def _normalize_author(self, author: Optional[str]) -> str:
        """ì‘ê°€ëª… ì •ê·œí™”
        
        Args:
            author: ì›ë³¸ ì‘ê°€ëª…
        
        Returns:
            ì •ê·œí™”ëœ ì‘ê°€ëª…
        """
        if not author:
            return "ì‘ê°€ë¯¸ìƒ"
        
        # íŒ¨í„´ ì œê±°
        for pattern in self.rules.author["remove_patterns"]:
            author = re.sub(pattern, "", author)
        
        # ìµœëŒ€ ê¸¸ì´
        max_len = self.rules.author["max_length"]
        if len(author.encode("utf-8")) > max_len:
            author_bytes = author.encode("utf-8")[:max_len]
            author = author_bytes.decode("utf-8", errors="ignore")
        
        return author.strip()
    
    def _format_tags(self, tags: List[str]) -> str:
        """íƒœê·¸ í¬ë§·
        
        Args:
            tags: íƒœê·¸ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            "íƒœê·¸1,íƒœê·¸2,íƒœê·¸3" í˜•ì‹
        """
        if not tags:
            return ""
        
        # ìš°ì„ ìˆœìœ„ íƒœê·¸ ë¨¼ì €
        priority = self.rules.tags["priority"]
        priority_tags = [t for t in tags if t in priority]
        other_tags = [t for t in tags if t not in priority]
        
        # í•©ì¹˜ê¸°
        sorted_tags = priority_tags + other_tags
        
        # ìµœëŒ€ ê°œìˆ˜
        max_count = self.rules.tags["max_in_filename"]
        selected_tags = sorted_tags[:max_count]
        
        # êµ¬ë¶„ìë¡œ ê²°í•©
        separator = self.rules.tags["separator"]
        return separator.join(selected_tags)
    
    def _sanitize_filename(self, filename: str) -> str:
        """ê¸ˆì§€ ë¬¸ì ì œê±°
        
        Args:
            filename: ì›ë³¸ íŒŒì¼ëª…
        
        Returns:
            ì •ë¦¬ëœ íŒŒì¼ëª…
        """
        forbidden = self.rules.filename["forbidden_chars"]
        replacement = self.rules.filename["replacement_char"]
        
        for char in forbidden:
            filename = filename.replace(char, replacement)
        
        return filename
    
    def _truncate_filename(self, filename: str, ext: str) -> str:
        """íŒŒì¼ëª… ê¸¸ì´ ì œí•œ
        
        Args:
            filename: íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
            ext: í™•ì¥ì
        
        Returns:
            ì˜ë¦° íŒŒì¼ëª…
        """
        max_len = self.rules.filename["max_total_length"]
        ext_len = len(ext.encode("utf-8"))
        available = max_len - ext_len
        
        filename_bytes = filename.encode("utf-8")
        if len(filename_bytes) > available:
            filename_bytes = filename_bytes[:available]
            filename = filename_bytes.decode("utf-8", errors="ignore")
        
        return filename
    
    def _apply_renames(self, file_id: int, old_name: str, new_name: str) -> bool:
        """ì‹¤ì œ íŒŒì¼ëª… ë³€ê²½ ì‹¤í–‰
        
        Args:
            file_id: íŒŒì¼ ID
            old_name: ê¸°ì¡´ íŒŒì¼ëª…
            new_name: ìƒˆ íŒŒì¼ëª…
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        conn = self.db.connect()
        cursor = conn.cursor()
        
        # íŒŒì¼ ê²½ë¡œ ì¡°íšŒ
        cursor.execute("SELECT file_path FROM files WHERE id = ?", (file_id,))
        row = cursor.fetchone()
        if not row:
            logger.error(f"File not found in DB: ID {file_id}")
            return False
            
        old_path = Path(row[0])
        if not old_path.exists():
            logger.error(f"File not found on disk: {old_path}")
            return False
            
        # ìƒˆ ê²½ë¡œ ìƒì„±
        new_path = old_path.with_name(new_name)
        
        try:
            # ì‹¤ì œ ì´ë¦„ ë³€ê²½
            old_path.rename(new_path)
            
            # DBì˜ file_path, file_name ì—…ë°ì´íŠ¸
            cursor.execute("""
                UPDATE files 
                SET file_path = ?, file_name = ?
                WHERE id = ?
            """, (str(new_path), new_path.stem, file_id))
            
            conn.commit()
            logger.info(f"   [Rename Executed] {old_path.name} -> {new_name}")
            return True
        except Exception as e:
            logger.error(f"Failed to rename file: {e}")
            return False
    
    def save_rename_plan(self, file_id: int, old_name: str, new_name: str) -> None:
        """íŒŒì¼ëª… ë³€ê²½ ê³„íš ì €ì¥
        
        Args:
            file_id: íŒŒì¼ ID
            old_name: ê¸°ì¡´ íŒŒì¼ëª…
            new_name: ìƒˆ íŒŒì¼ëª…
        """
        conn = self.db.connect()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO rename_plan (file_id, old_name, new_name)
            VALUES (?, ?, ?)
        """, (file_id, old_name, new_name))
        
        # processing_state ì—…ë°ì´íŠ¸
        cursor.execute("""
            UPDATE processing_state
            SET stage3_rename = 1, last_stage = 'stage3'
            WHERE file_id = ?
        """, (file_id,))
        
        conn.commit()
    
    def generate_mapping_file(self, plans: List[Tuple[str, str]]) -> str:
        """ê²€ìˆ˜ìš© ë§¤í•‘ íŒŒì¼ ìƒì„±
        
        Args:
            plans: [(old_name, new_name), ...]
        
        Returns:
            ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = Path(f"data/mapping_result_{timestamp}.txt")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("=" * 100 + "\n")
            f.write(f"íŒŒì¼ëª… ë³€ê²½ ê³„íš - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 100 + "\n\n")
            
            for old_name, new_name in plans:
                f.write(f"{old_name}\n")
                f.write(f"  â†’ {new_name}\n\n")
        
        logger.info(f"âœ… Mapping file created: {output_path}")
        return str(output_path)
    
    def run(self, limit: Optional[int] = None) -> Dict[str, Any]:
        """Stage 3 ì‹¤í–‰"""
        logger.info("=" * 50)
        logger.info("Stage 3: Filename Generation")
        logger.info("=" * 50)
        
        # ëŒ€ê¸° íŒŒì¼ ì¡°íšŒ
        files = self.get_pending_files(limit)
        
        if not files:
            logger.warning("No files to process")
            return {"total": 0, "renamed": 0, "mapping_file": None}
        
        result = self.process_files(files)
        
        logger.info("=" * 50)
        logger.info(f"âœ… Stage 3 Complete: {result['renamed']} files renamed")
        if result['mapping_file']:
            logger.info(f"ğŸ“„ Mapping file: {result['mapping_file']}")
        logger.info("=" * 50)
        
        return result

    def process_single_file(self, file_id: int) -> bool:
        """ë‹¨ì¼ íŒŒì¼ì— ëŒ€í•´ ëª…ëª… ê·œì¹™ ì¬ì ìš© ë° ì´ë¦„ ë³€ê²½ (M-49)"""
        conn = self.db.connect()
        cursor = conn.cursor()
        
        query = """
            SELECT f.id, f.file_path, f.file_name, f.file_ext, n.title, n.author, n.genre, 
                   n.tags, n.status, n.episode_range, n.rating, n.chapter_count, n.reconciliation_log
            FROM files f
            JOIN novels n ON f.novel_id = n.id
            WHERE f.id = ?
        """
        cursor.execute(query, (file_id,))
        row = cursor.fetchone()
        if not row:
            return False
            
        file_info = {
            "id": row[0],
            "file_path": row[1],
            "filename": row[2],
            "ext": row[3],
            "title": row[4],
            "author": row[5],
            "genre": row[6],
            "tags": self._parse_tags(row[7]) if row[7] else [],
            "status": row[8],
            "episode_range": row[9],
            "rating": row[10],
            "chapter_count": row[11],
            "reconciliation_log": row[12],
            "file_name": row[2] # generate_filenameì—ì„œ metadata.get("filename") ì‚¬ìš©í•˜ë¯€ë¡œ ë§ì¶°ì¤Œ
        }
        # generate_filename ë‚´ë¶€ì—ì„œ metadata["filename"]ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í‚¤ë¥¼ ë§ì¶°ì¤Œ
        file_info["filename"] = row[2]
        
        new_name = self.generate_filename(file_info)
        return self._apply_renames(file_info["id"], file_info["filename"], new_name)

    def process_files(self, files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬"""
        plans = []
        success_count = 0
        for i, file in enumerate(files):
            new_name = self.generate_filename(file)
            
            if self._apply_renames(file["id"], file["filename"], new_name):
                self.save_rename_plan(file["id"], file["filename"], new_name)
                plans.append((file["filename"], new_name))
                success_count += 1
            else:
                logger.error(f"  âŒ Failed to rename {file['filename']}")
        
        mapping_file = self.generate_mapping_file(plans) if plans else None
        return {
            "total": len(files),
            "renamed": success_count,
            "mapping_file": mapping_file
        }

    def _parse_tags(self, tags_raw: str) -> List[str]:
        """íƒœê·¸ ë¬¸ìì—´ íŒŒì‹± (JSON ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´)"""
        if not tags_raw:
            return []
            
        tags_raw = tags_raw.strip()
        if tags_raw.startswith("["):
            try:
                import json
                tags_list = json.loads(tags_raw)
                if isinstance(tags_list, list):
                    return [str(t).strip() for t in tags_list if t]
            except:
                pass
        
        # ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        return [t.strip() for t in tags_raw.split(",") if t.strip()]
